# model
model_version: v1.2
pretrained_model_path: models/PixArt-Sigma-XL-2-2K-MS.ckpt
model_max_length: 300
freeze_y_embedder: True

noise_scheduler: fm
sample_method: logit-normal
use_timestep_transform: True

vae_type: OpenSoraVAE_V1_2
vae_checkpoint: models/OpenSora-VAE-v1.2/model.ckpt
vae_dtype: bf16
vae_micro_batch_size: 4
vae_micro_frame_size: 17  # keep it unchanged for the best results

enable_flash_attention: True
use_recompute: True

# data
num_parallel_workers: 2
num_workers_dataset: 2
prefetch_size: 2
max_rowsize: 256

# precision
amp_level: "O2"
dtype: bf16
loss_scaler_type: static
init_loss_scale: 1

# mindspore params, refer to https://www.mindspore.cn/docs/zh-CN/r2.3.1/api_python/mindspore/mindspore.set_context.html
max_device_memory: "59GB"
jit_level: "O1"
manual_pad: True

# training hyper-params
scheduler: "constant"
start_learning_rate: 1.e-4
end_learning_rate: 1.e-4
warmup_steps: 1000

clip_grad: True
max_grad_norm: 1.0
use_ema: True
ema_decay: 0.99

optim: "adamw_re"
optim_eps: 1e-15
weight_decay: 0.

# epochs: 2
train_steps: 30000
ckpt_save_steps:  500

mask_ratios:
  random: 0.05
  interpolate: 0.005
  quarter_random: 0.005
  quarter_head: 0.005
  quarter_tail: 0.005
  quarter_head_tail: 0.005
  image_random: 0.025
  image_head: 0.05
  image_tail: 0.025
  image_head_tail: 0.025


image_size:
    - 256
    - 256
num_frames: 1

# ---------- Validation ----------
validate: False
