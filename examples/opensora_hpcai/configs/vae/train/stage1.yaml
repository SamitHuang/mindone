# model
model_type: "OpenSoraVAE_V1_2"
freeze_vae_2d: True
pretrained_model_path: "models/sdxl_vae/model.ckpt"

# loss
perceptual_loss_weight: 0.1
kl_loss_weight: 1.e-6
use_real_rec_loss: False 
use_z_rec_loss: True
use_image_identity_loss: True
mixed_strategy: "mixed_video_image" # TODO: test it in dynamic mode
mixed_image_ratio: 0.2

# data
dataset_name: "video"
csv_path: "../videocomposer/datasets/webvid5_copy.csv"
video_folder: "../videocomposer/datasets/webvid5"
frame_stride: 1
num_frames: 17
image_size: 256

micro_frame_size: null
# TODO: set micro_batch_size and micro_frame_size to None. The default value is 4, 17
# flip: True

# training recipe
seed: 42
use_discriminator: False
dtype: "fp16"   # TODO: try bf16
batch_size: 1
clip_grad: True
max_grad_norm: 1.0
start_learning_rate: 1.e-5
scale_lr: False
use_recompute: False

epochs: 2000
ckpt_save_interval: 100
init_loss_scale: 1.

scheduler: "constant"
use_ema: False

output_path: "outputs/causal_vae"
